pipeline {
    agent any
    environment {
        NAMESPACE = "airflow"
        REPO_NAME = '' // Será definido dinamicamente no estágio de preparação
        KUBECONFIG_PATH = '' // Deve ser definido no Jenkins ou passado como um parâmetro
        GLOBAL_ENV = '' // Será definido dinamicamente com base no nome da branch
    }
    stages {
        stage('Preparation') {
            steps {
                script {
                    try {
                        echo 'Tentando extrair o nome do repositório...'
                        REPO_NAME = sh(script: 'basename -s .git `git config --get remote.origin.url`', returnStdout: true).trim()
                        echo "Nome do repositório: ${REPO_NAME}"

                        echo 'Tentando compactar o repositório...'
                        sh 'tar -czvf repo.tar.gz .'
                        echo 'Repositório compactado com sucesso.'
                    } catch (Exception e) {
                        echo "Erro no estágio de preparação: ${e.getMessage()}"
                        error "Falha no estágio de preparação."
                    }
                }
            }
        }
        stage('DAG Deployment') {
            when {
                anyOf {
                    branch 'main'
                    branch 'uat'
                    branch 'dev'
                }
            }
            steps {
                script {
                    def envValue = ''
                    def clusterName = ''
                    def profile = ''

                    if (BRANCH_NAME == 'main') {
                        envValue = 'prod'
                        clusterName = "agribusiness-eks-${envValue}"
                        profile = "eec-agribusiness-${envValue}"
                    } else if (BRANCH_NAME == 'uat') {
                        envValue = 'uat'
                        clusterName = "agribusiness-eks-${envValue}"
                        profile = "eec-agribusiness-${envValue}"
                    } else if (BRANCH_NAME == 'dev') {
                        envValue = 'dev'
                        clusterName = "agribusiness-eks-${envValue}"
                        profile = "eec-agribusiness-${envValue}"
                    }

                    withEnv(["GLOBAL_ENV=${envValue}"]) {
                        // Atualiza o kubeconfig, garantindo que o contexto correto esteja configurado como padrão
                        sh "AWS_REGION=sa-east-1 AWS_PROFILE=${profile} aws eks update-kubeconfig --name ${clusterName} --kubeconfig ${KUBECONFIG_PATH}"

                        // Teste de conectividade com o cluster
                        def nodes = sh(script: "KUBECONFIG=${KUBECONFIG_PATH} kubectl get nodes", returnStdout: true).trim()
                        echo "Nodes no cluster: \n${nodes}"

                        // Escreve o arquivo YAML no workspace
                        writeFile file: 'pod.yaml', text: """
                        apiVersion: v1
                        kind: Pod
                        metadata:
                          name: deploy-dag-${REPO_NAME}
                          namespace: ${NAMESPACE}
                        spec:
                          containers:
                          - name: deploy-dags
                            image: alpine
                            command: ["/bin/sh", "-c"]
                            args:
                            - |
                              apk add --no-cache tar
                              echo "Esperando por repo.tar.gz em /tmp"
                              while [ ! -f /tmp/repo.tar.gz ]; do sleep 2; done
                              echo "Arquivo repo.tar.gz encontrado, continuando..."
                              if [ -d "/dags/${REPO_NAME}" ]; then
                                echo "Diretório encontrado, removendo..."
                                rm -rf /dags/${REPO_NAME}"
                              fi
                              echo "Criando diretório ${REPO_NAME}..."
                              mkdir -p /dags/${REPO_NAME}
                              tar -xzvf /tmp/repo.tar.gz -C /dags/${REPO_NAME}
                              echo "Descompactação concluída. Removendo o arquivo repo.tar.gz..."
                              rm /tmp/repo.tar.gz
                            volumeMounts:
                            - name: airflow-dags
                              mountPath: /dags
                          restartPolicy: Never
                          volumes:
                          - name: airflow-dags
                            persistentVolumeClaim:
                              claimName: airflow-dags
                        """

                        // Aplica o arquivo YAML
                        def kubectlApplyOutput = sh(script: "KUBECONFIG=${KUBECONFIG_PATH} kubectl apply -f pod.yaml", returnStdout: true).trim()
                        echo "Saída do kubectl apply: ${kubectlApplyOutput}"

                        // Aguarda até que o Pod esteja em execução
                        echo 'Aguardando o Pod iniciar...'
                        sh """
                        KUBECONFIG=${KUBECONFIG_PATH} kubectl wait --for=condition=ready pod deploy-dag-${REPO_NAME} -n ${NAMESPACE} --timeout=600s
                        """

                        // Obtenha o nome do Pod em execução
                        def podName = sh(script: "KUBECONFIG=${KUBECONFIG_PATH} kubectl get pods --namespace=${NAMESPACE} -l app=deploy-dag-${REPO_NAME} -o=jsonpath='{.items[0].metadata.name}'", returnStdout: true).trim()
                        echo "O Pod está em execução no Pod: ${podName}"

                        // Copie o repo.tar.gz para o Pod
                        echo 'Copiando repo.tar.gz para o Pod...'
                        sh """
                        KUBECONFIG=${KUBECONFIG_PATH} kubectl cp repo.tar.gz ${NAMESPACE}/${podName}:/tmp/repo.tar.gz
                        """

                        // Monitora o status do Pod para verificar se a tarefa foi concluída com sucesso.
                        def podStatus = ''
                        def maxRetries = 20
                        for (int i = 0; i < maxRetries; i++) {
                            podStatus = sh(script: "KUBECONFIG=${KUBECONFIG_PATH} kubectl get pod ${podName} -n ${NAMESPACE} -o=jsonpath='{.status.phase}'", returnStdout: true).trim()

                            if (podStatus == 'Succeeded') {
                                echo "O Pod concluiu a tarefa com sucesso."
                                break
                            } else if (podStatus == 'Failed') { // O status do Pod é 'Failed', algo deu errado
                                // Obtém e imprime os logs do Pod para diagnóstico
                                echo "O Pod falhou. Aqui estão os logs:"
                                sh "KUBECONFIG=${KUBECONFIG_PATH} kubectl logs ${podName} -n ${NAMESPACE}"
        
                                // Imprime os eventos do Pod para entender o que aconteceu
                                echo "Eventos do Pod:"
                                sh "KUBECONFIG=${KUBECONFIG_PATH} kubectl get events --field-selector involvedObject.name=${podName} -n ${NAMESPACE}"
        
                                error "O Pod falhou, verifique os logs e eventos para detalhes."
                            } else if (i < maxRetries - 1) {
                                echo "A tarefa ainda não está completa. Tentativa ${i + 1} de ${maxRetries}. Aguardando 30 segundos antes da próxima verificação..."
                                sleep 30
                            } else {
                                error "A tarefa não foi concluída após ${maxRetries} tentativas. O processo falhou."
                            }
                        }

                        // Após a conclusão, delete o Pod
                        echo 'Deletando o Pod...'
                        sh """
                        KUBECONFIG=${KUBECONFIG_PATH} kubectl delete pod ${podName} -n ${NAMESPACE}
                        """
                    }
                }
            }
        }
    }
}
