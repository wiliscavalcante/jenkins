pipeline {
    agent any
    environment {
        NAMESPACE = "sensoriamento"
    }
    stages {
        stage('Delivery dags') {
            when {
                anyOf {
                    branch 'main'
                    branch 'uat'
                    branch 'dev'
                }
            }
            steps {
                script {
                    def env = ''
                    def clusterName = ""
                    def profile = ""

                    // Definindo o nome da pasta DAG com base no nome do reposit√≥rio
                    def repoUrl = env.GIT_URL
                    def dagFolderName = repoUrl.split('/')[-1].replaceAll('.git$', '')

                    if (BRANCH_NAME == 'main') {
                        env = 'prod'
                    } else if (BRANCH_NAME == 'uat') {
                        env = 'uat'
                    } else if (BRANCH_NAME == 'dev') {
                        env = 'dev'
                    }

                    clusterName = "agribusiness-eks-${env}"
                    profile = "eec-agribusiness-${env}"

                    // Atualizar o kubeconfig
                    sh "AWS_REGION=sa-east-1 AWS_PROFILE=${profile} aws eks update-kubeconfig --name ${clusterName}"
                    
                    // Criar o job do Kubernetes
                    sh '''
                        cat <<EOF | kubectl apply -f -
                        apiVersion: batch/v1
                        kind: Job
                        metadata:
                          name: dag-delivery-job
                          namespace: ${NAMESPACE}
                        spec:
                          template:
                            spec:
                              containers:
                              - name: ubuntu
                                image: ubuntu:latest
                                command: ["/bin/sleep", "infinity"]
                                volumeMounts:
                                - name: airflow-dags
                                  mountPath: /dags
                              volumes:
                              - name: airflow-dags
                                persistentVolumeClaim:
                                  claimName: airflow-dags-pvc
                              restartPolicy: Never
                          backoffLimit: 1
                        EOF
                    '''

                    // Pegar o nome do pod gerado pelo job
                    def jobPod = sh(script: "kubectl get pods -n ${NAMESPACE} -l job-name=dag-delivery-job -o jsonpath='{.items[0].metadata.name}'", returnStdout: true).trim()

                    // Remover a pasta antiga da DAG (caso exista)
                    sh "kubectl exec ${jobPod} -n ${NAMESPACE} -- rm -rf /dags/${dagFolderName}"

                    // Copiar pasta da DAG para o Pod do Job
                    sh "kubectl cp ${dagFolderName} ${NAMESPACE}/${jobPod}:/dags/${dagFolderName}"

                    // Deletar o job
                    sh "kubectl delete job dag-delivery-job -n ${NAMESPACE}"
                }
            }
        }
    }
}
