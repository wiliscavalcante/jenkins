pipeline {
    agent any
    environment {
        NAMESPACE = "airflow"
        REPO_NAME = '' // Será definido dinamicamente no estágio de preparação
        KUBECONFIG_PATH = '' // Deve ser definido no Jenkins ou passado como um parâmetro
        GLOBAL_ENV = '' // Será definido dinamicamente com base no nome da branch
    }
    stages {
        stage('Preparation') {
            steps {
                script {
                    try {
                        echo 'Tentando extrair o nome do repositório...'
                        REPO_NAME = sh(script: 'basename -s .git `git config --get remote.origin.url`', returnStdout: true).trim()
                        echo "Nome do repositório: ${REPO_NAME}"

                        echo 'Tentando compactar o repositório...'
                        sh 'tar -czvf repo.tar.gz .'
                        echo 'Repositório compactado com sucesso.'
                    } catch (Exception e) {
                        echo "Erro no estágio de preparação: ${e.getMessage()}"
                        error "Falha no estágio de preparação."
                    }
                }
            }
        }
        stage('DAG Deployment') {
            when {
                anyOf {
                    branch 'main'
                    branch 'uat'
                    branch 'dev'
                }
            }
            steps {
                script {
                    def envValue = ''
                    def clusterName = ''
                    def profile = ''

                    if (BRANCH_NAME == 'main') {
                        envValue = 'prod'
                        clusterName = "agribusiness-eks-${envValue}"
                        profile = "eec-agribusiness-${envValue}"
                    } else if (BRANCH_NAME == 'uat') {
                        envValue = 'uat'
                        clusterName = "agribusiness-eks-${envValue}"
                        profile = "eec-agribusiness-${envValue}"
                    } else if (BRANCH_NAME == 'dev') {
                        envValue = 'dev'
                        clusterName = "agribusiness-eks-${envValue}"
                        profile = "eec-agribusiness-${envValue}"
                    }

                    withEnv(["GLOBAL_ENV=${envValue}"]) {
                        // Atualiza o kubeconfig, garantindo que o contexto correto esteja configurado como padrão
                        sh "AWS_REGION=sa-east-1 AWS_PROFILE=${profile} aws eks update-kubeconfig --name ${clusterName} --kubeconfig ${KUBECONFIG_PATH}"

                        // Teste de conectividade com o cluster
                        def nodes = sh(script: "KUBECONFIG=${KUBECONFIG_PATH} kubectl get nodes", returnStdout: true).trim()
                        echo "Nodes no cluster: \n${nodes}"

                        // Escreve o arquivo YAML no workspace
                        writeFile file: 'job.yaml', text: """
                        apiVersion: batch/v1
                        kind: Job
                        metadata:
                          name: deploy-dag-${REPO_NAME}
                          namespace: ${NAMESPACE}
                        spec:
                          template:
                            spec:
                              containers:
                              - name: deploy-dags
                                image: alpine
                                command: ["/bin/sh", "-c"]
                                args:
                                - |
                                  apk add --no-cache tar
                                  echo "Esperando por repo.tar.gz em /tmp"
                                  while [ ! -f /tmp/repo.tar.gz ]; do sleep 2; done
                                  echo "Arquivo repo.tar.gz encontrado, continuando..."
                                  if [ -d "/dags/${REPO_NAME}" ]; then
                                    echo "Diretório encontrado, removendo..."
                                    rm -rf /dags/${REPO_NAME}"
                                  fi
                                  echo "Criando diretório ${REPO_NAME}..."
                                  mkdir -p /dags/${REPO_NAME}
                                  tar -xzvf /tmp/repo.tar.gz -C /dags/${REPO_NAME}
                                  echo "Descompactação concluída. Removendo o arquivo repo.tar.gz..."
                                  rm /tmp/repo.tar.gz
                                volumeMounts:
                                - name: airflow-dags
                                  mountPath: /dags
                              restartPolicy: Never
                              volumes:
                              - name: airflow-dags
                                persistentVolumeClaim:
                                  claimName: airflow-dags
                        """

                        // Aplica o arquivo YAML
                        def kubectlApplyOutput = sh(script: "KUBECONFIG=${KUBECONFIG_PATH} kubectl apply -f job.yaml", returnStdout: true).trim()
                        echo "Saída do kubectl apply: ${kubectlApplyOutput}"

                        // Checa se o job foi criado
                        def jobExists = sh(script: "KUBECONFIG=${KUBECONFIG_PATH} kubectl get job deploy-dag-${REPO_NAME} -n ${NAMESPACE}", returnStdout: true).trim()
                        if (jobExists == '') {
                            error "O job não existe. A criação do job falhou."
                        }

                        // Verifica o status do Job
                        def jobStatus = ''
                        def maxRetries = 10
                        for (int i = 0; i < maxRetries; i++) {
                            jobStatus = sh(script: "KUBECONFIG=${KUBECONFIG_PATH} kubectl get job deploy-dag-${REPO_NAME} -n ${NAMESPACE} -o=jsonpath='{.status.conditions[?(@.type==\"Complete\")].status}'", returnStdout: true).trim()

                            if (jobStatus == 'True') {
                                echo "O job foi concluído com sucesso."
                                break
                            } else if (i < maxRetries - 1) {
                                echo "O job ainda não está completo. Tentativa ${i + 1} de ${maxRetries}. Aguardando 30 segundos antes da próxima verificação..."
                                sleep 30
                            } else {
                                error "O job não foi concluído após ${maxRetries} tentativas. O processo falhou."
                            }
                        }
                    }
                }
            }
        }
    }
    post {
        always {
            // Lógica para limpeza ou notificações, se necessário
            echo 'Execução do Pipeline concluída.'
        }
    }
}
